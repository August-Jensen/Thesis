{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bc2afb0-9d22-46a6-b2c1-1e33f9acced3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector of constants (A): [0. 0. 0.]\n",
      "Matrix of autoregressive parameters (B): [[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('3.csv')\n",
    "\n",
    "# Convert the DataFrame to a NumPy array\n",
    "data = df.values\n",
    "\n",
    "# Set T and K\n",
    "T, K = data.shape\n",
    "K = 3  # Override K as per your requirement\n",
    "\n",
    "def create_parameters(K, p=1):\n",
    "    \"\"\"\n",
    "    Initializes the parameters for the VAR(p) model.\n",
    "    \n",
    "    Parameters:\n",
    "    - K: The number of time series.\n",
    "    - p: The order of the VAR model.\n",
    "    \n",
    "    Returns:\n",
    "    - A: The vector of constants for each time series (K-dimensional).\n",
    "    - B: The matrices of autoregressive parameters (KxK for each lag).\n",
    "    \"\"\"\n",
    "    A = np.zeros(K)  # Vector of constants\n",
    "    B = np.zeros((K, K * p))  # Autoregressive parameters for p lags\n",
    "    \n",
    "    return A, B\n",
    "\n",
    "# Example usage\n",
    "A, B = create_parameters(K)\n",
    "print(\"Vector of constants (A):\", A)\n",
    "print(\"Matrix of autoregressive parameters (B):\", B)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4176fc-9024-49b2-b668-8a0c582ed965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "Log likelihood: 10348.117397080463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K = 3  # Number of time series (set to 3 as per your requirement)\n",
    "p = 1  # Order of the VAR model\n",
    "\n",
    "def calculate_log_likelihood(params, data, K, p):\n",
    "    \"\"\"\n",
    "    Calculates the log likelihood of a VAR(p) model.\n",
    "    \n",
    "    Parameters:\n",
    "    - params: A flattened array containing all parameters (A and B matrices flattened).\n",
    "    - data: The observed data as a NumPy array (T x K).\n",
    "    - K: The number of time series.\n",
    "    - p: The order of the VAR model.\n",
    "    \n",
    "    Returns:\n",
    "    - The log likelihood of the model.\n",
    "    \"\"\"\n",
    "    T, _ = data.shape\n",
    "    \n",
    "    # Reshape params into A and B matrices\n",
    "    A = params[:K]\n",
    "    B = params[K:].reshape((K, K*p))\n",
    "    \n",
    "    # Construct the lagged Y matrix\n",
    "    Y_lagged = np.hstack([data[p-i:-i] for i in range(1, p+1)])\n",
    "    Y = data[p:]  # Match dimensions\n",
    "    \n",
    "    # Calculate predicted values\n",
    "    Y_pred = np.dot(Y_lagged, B.T) + A\n",
    "    \n",
    "    # Calculate residuals\n",
    "    residuals = Y - Y_pred\n",
    "    \n",
    "    # Estimate covariance matrix of residuals\n",
    "    Sigma = np.cov(residuals.T)\n",
    "    \n",
    "    # Calculate log likelihood\n",
    "    term1 = -T * K / 2 * np.log(2 * np.pi)\n",
    "    term2 = -T / 2 * np.log(np.linalg.det(Sigma))\n",
    "    term3 = -1/2 * np.sum(np.dot(residuals, np.linalg.inv(Sigma)) * residuals)\n",
    "    log_likelihood = term1 + term2 + term3\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# Flattening A and B into a single array of parameters\n",
    "# Initial A and B for example purposes\n",
    "A_initial = np.zeros(K)  # Vector of constants\n",
    "B_initial = np.zeros((K, K*p))  # Autoregressive parameters for p lags\n",
    "params_initial = np.concatenate([A_initial, B_initial.flatten()])\n",
    "print(params_initial)\n",
    "# Use your actual data and initial parameters\n",
    "log_likelihood = calculate_log_likelihood(params_initial, data, K, p)\n",
    "print(\"Log likelihood:\", log_likelihood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92696233-eeca-4870-9546-69c3af0e1f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def negative_log_likelihood(params, data, K, p):\n",
    "    \"\"\"\n",
    "    Returns the negative log likelihood of the VAR model.\n",
    "    \n",
    "    This is the function to be minimized.\n",
    "\n",
    "    Parameters:\n",
    "    - params: The parameters of the VAR model (flattened A and B matrices).\n",
    "    - data: The observed data as a NumPy array (T x K).\n",
    "    - K: The number of time series.\n",
    "    - p: The order of the VAR model.\n",
    "    \"\"\"\n",
    "    # The negative of the log likelihood is returned because we are minimizing\n",
    "    return -calculate_log_likelihood(params, data, K, p)\n",
    "\n",
    "def estimate_var_parameters(data, K, p, initial_params):\n",
    "    \"\"\"\n",
    "    Estimates the VAR model parameters by minimizing the negative log likelihood.\n",
    "\n",
    "    Parameters:\n",
    "    - data: The observed data as a NumPy array (T x K).\n",
    "    - K: The number of time series.\n",
    "    - p: The order of the VAR model.\n",
    "    - initial_params: Initial guesses for the parameters (flattened A and B).\n",
    "\n",
    "    Returns:\n",
    "    - The result of the optimization procedure (OptimizeResult object).\n",
    "    \"\"\"\n",
    "    result = minimize(negative_log_likelihood, initial_params, args=(data, K, p), method='L-BFGS-B')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a1c2b1b-3c38-40c9-8822-69df485dc617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization was successful.\n",
      "Optimized Parameters: [ 0.00032334  0.00046835 -0.00037058 -0.10738508 -0.03853695  0.1132595\n",
      " -0.03784116 -0.11854587  0.08826391  0.04238161  0.04306515 -0.01172047]\n",
      "Optimized A: [ 0.00032334  0.00046835 -0.00037058]\n",
      "Optimized B: [[-0.10738508 -0.03853695  0.1132595 ]\n",
      " [-0.03784116 -0.11854587  0.08826391]\n",
      " [ 0.04238161  0.04306515 -0.01172047]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize A and B with zeros or some other initial guess\n",
    "initial_A = np.zeros(K)  # Vector of constants\n",
    "initial_B = np.zeros((K, K*p))  # Autoregressive parameters for p lags\n",
    "initial_params = np.concatenate([initial_A, initial_B.flatten()])  # Flatten the parameters\n",
    "\n",
    "# Call the estimation function\n",
    "result = estimate_var_parameters(data, K, p, initial_params)\n",
    "\n",
    "# Results\n",
    "if result.success:\n",
    "    print(\"Optimization was successful.\")\n",
    "    optimized_params = result.x\n",
    "    print(\"Optimized Parameters:\", optimized_params)\n",
    "else:\n",
    "    print(\"Optimization failed.\")\n",
    "    print(\"Reason:\", result.message)\n",
    "\n",
    "# Reshape the optimized parameters back into A and B if needed\n",
    "optimized_A = optimized_params[:K]\n",
    "optimized_B = optimized_params[K:].reshape(K, K*p)\n",
    "print(\"Optimized A:\", optimized_A)\n",
    "print(\"Optimized B:\", optimized_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0cba9f5-39f5-483a-b0a8-5cf6972e936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Summary of Regression Results   \n",
      "==================================\n",
      "Model:                         VAR\n",
      "Method:                        OLS\n",
      "Date:           Fri, 15, Mar, 2024\n",
      "Time:                     06:06:27\n",
      "--------------------------------------------------------------------\n",
      "No. of Equations:         3.00000    BIC:                   -29.0844\n",
      "Nobs:                     1004.00    HQIC:                  -29.1208\n",
      "Log likelihood:           10368.0    FPE:                2.20448e-13\n",
      "AIC:                     -29.1431    Det(Omega_mle):     2.17834e-13\n",
      "--------------------------------------------------------------------\n",
      "Results for equation ACWI\n",
      "==========================================================================\n",
      "             coefficient       std. error           t-stat            prob\n",
      "--------------------------------------------------------------------------\n",
      "const           0.000328         0.000427            0.768           0.443\n",
      "L1.ACWI        -0.075152         0.148917           -0.505           0.614\n",
      "L1.SPY         -0.069341         0.142528           -0.487           0.627\n",
      "L1.TLT          0.113031         0.036657            3.083           0.002\n",
      "==========================================================================\n",
      "\n",
      "Results for equation SPY\n",
      "==========================================================================\n",
      "             coefficient       std. error           t-stat            prob\n",
      "--------------------------------------------------------------------------\n",
      "const           0.000473         0.000447            1.057           0.290\n",
      "L1.ACWI        -0.003421         0.156046           -0.022           0.983\n",
      "L1.SPY         -0.151441         0.149351           -1.014           0.311\n",
      "L1.TLT          0.088019         0.038412            2.291           0.022\n",
      "==========================================================================\n",
      "\n",
      "Results for equation TLT\n",
      "==========================================================================\n",
      "             coefficient       std. error           t-stat            prob\n",
      "--------------------------------------------------------------------------\n",
      "const          -0.000371         0.000372           -0.996           0.319\n",
      "L1.ACWI         0.039750         0.129741            0.306           0.759\n",
      "L1.SPY          0.045430         0.124175            0.366           0.714\n",
      "L1.TLT         -0.011385         0.031937           -0.356           0.721\n",
      "==========================================================================\n",
      "\n",
      "Correlation matrix of residuals\n",
      "            ACWI       SPY       TLT\n",
      "ACWI    1.000000  0.977663 -0.153071\n",
      "SPY     0.977663  1.000000 -0.160640\n",
      "TLT    -0.153071 -0.160640  1.000000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Estimated A (intercept/terms) from statsmodels:\n",
      " [ 0.00032775  0.00047306 -0.00037058]\n",
      "\n",
      "Estimated B (autoregressive parameters) from statsmodels:\n",
      " [[-0.07515212 -0.00342125  0.03974991]\n",
      " [-0.06934101 -0.1514413   0.0454299 ]\n",
      " [ 0.11303057  0.08801938 -0.01138539]]\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import VAR\n",
    "\n",
    "# Assuming your DataFrame 'df' is already loaded from '3.csv'\n",
    "# df = pd.read_csv('3.csv')\n",
    "\n",
    "# Preparing the data (ensure no missing values and it's stationary)\n",
    "# For VAR models, it's crucial to ensure the data is stationary. You may need to difference or transform it.\n",
    "\n",
    "data2 = df\n",
    "\n",
    "# Fit VAR model using statsmodels\n",
    "model = VAR(data2)\n",
    "results = model.fit(maxlags=1, ic='aic')  # Here, we use AIC to choose the best lag order up to 1. Adjust as necessary.\n",
    "\n",
    "# Print summary of the fitted model\n",
    "print(results.summary())\n",
    "\n",
    "# Extracting estimated parameters for comparison\n",
    "A_statsmodels = results.params.iloc[0].values  # Intercept terms (constants)\n",
    "B_statsmodels = results.params.iloc[1:].values  # Autoregressive coefficients\n",
    "\n",
    "print(\"\\nEstimated A (intercept/terms) from statsmodels:\\n\", A_statsmodels)\n",
    "print(\"\\nEstimated B (autoregressive parameters) from statsmodels:\\n\", B_statsmodels)\n",
    "\n",
    "# Assuming `optimized_A` and `optimized_B` are your optimized parameters from the custom estimation\n",
    "# print(\"Optimized A from custom estimation:\", optimized_A)\n",
    "# print(\"Optimized B from custom estimation:\", optimized_B)\n",
    "\n",
    "# Note: Before comparing, make sure the formats of A and B are compatible between the custom estimation and statsmodels results.\n",
    "\n",
    "# Here, you would directly compare the values of A_statsmodels and B_statsmodels with your optimized_A and optimized_B.\n",
    "# This could be done by looking at the differences, ratios, or by evaluating the models' predictive performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468a3610-237b-4d87-a11f-9bacad49ce4c",
   "metadata": {},
   "source": [
    "\n",
    "Optimization was successful.\n",
    "Optimized Parameters: [ 0.3967176   0.46135682  0.48737813  0.15284922  0.17526633 -0.08598358\n",
    " -0.09927688  0.01802577  0.15329777 -0.08297423 -0.05485256  0.09327762]\n",
    " \n",
    "Optimized A: [0.3967176  0.46135682 0.48737813]\n",
    "\n",
    "Optimized B: \n",
    "[[ 0.15284922  0.17526633 -0.08598358]\n",
    " [-0.09927688  0.01802577  0.15329777]\n",
    " [-0.08297423 -0.05485256  0.09327762]]\n",
    "\n",
    "\n",
    "Estimated A (intercept/terms) from statsmodels:\n",
    " [ 0.00032775  0.00047306 -0.00037058]\n",
    "\n",
    "Estimated B (autoregressive parameters) from statsmodels:\n",
    " [[-0.07515212 -0.00342125  0.03974991]\n",
    " [-0.06934101 -0.1514413   0.0454299 ]\n",
    " [ 0.11303057  0.08801938 -0.01138539]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c379c503-5255-4488-b0a4-dbcc6900b3c8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4078822011.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    Estimated A (intercept/terms) from statsmodels:\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Estimated A (intercept/terms) from statsmodels:\n",
    " [ 0.00040347  0.00055942 -0.00041654]\n",
    "\n",
    "Estimated B (autoregressive parameters) from statsmodels:\n",
    " [[-0.05866018  0.00894351  0.09763493]\n",
    " [-0.0796686  -0.16043477  0.00179141]\n",
    " [ 0.11113023  0.08568708 -0.02940672]\n",
    " [ 0.435087    0.47028072  0.21270671]\n",
    " [-0.30868078 -0.3442554  -0.17788739]\n",
    " [ 0.05054378  0.06193812 -0.13328895]\n",
    " [ 0.18438885  0.21882371  0.10355544]\n",
    " [-0.15850544 -0.18704238 -0.09058968]\n",
    " [ 0.0896783   0.09023644 -0.10620292]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ce88bb-5cd7-485e-9c85-f7f3c1c27669",
   "metadata": {},
   "outputs": [],
   "source": [
    "Optimized A: [0.29406983 0.4598727  0.33642975]\n",
    "Optimized B: [[ 0.09019945  0.18850645 -0.06585952  0.02080435  0.15970833 -0.05398002\n",
    "   0.02586116  0.14150846 -0.0566283 ]\n",
    " [-0.11949213  0.06700082  0.15567987  0.03886389  0.00660415 -0.24294738\n",
    "   0.00165449  0.06371084  0.10683534]\n",
    " [-0.08872433 -0.05476073  0.11257378 -0.05901685  0.09345693 -0.00376962\n",
    "   0.10836608 -0.00655298  0.17453902]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4357bee-a5eb-4f3d-9ea8-60fd89ffbb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.hess_inv.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d523b-138c-48ce-8e5f-2211919b4548",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3488d-adfa-4d48-8b21-df83f35327d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02dc1dff-3211-49ab-951b-51948083ba2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09073934-ac72-4f4a-9380-766b9893f97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
