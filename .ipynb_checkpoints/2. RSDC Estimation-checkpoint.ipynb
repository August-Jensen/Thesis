{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f7ccc7a-f3a0-415b-98aa-f111cb18fd71",
   "metadata": {},
   "source": [
    "# The CCC Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c37bf914-d715-4dac-a025-d2795b2e14b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def df_to_array(dataframe):\n",
    "    # Create Numpy Array\n",
    "    data_array = df.to_numpy().T\n",
    "    \n",
    "\n",
    "    # Get titles of columns for plotting\n",
    "    labels = df.columns.tolist()\n",
    "\n",
    "    return data_array, labels\n",
    "\n",
    "# Find the log-likelihood contributions of the univariate volatility\n",
    "def univariate_log_likelihood_contribution(x, sigma):\n",
    "    sigma = max(sigma, 1e-8)\n",
    "    return -0.5 * np.log(2 * np.pi) - np.log(sigma) - (x ** 2) / (2 * sigma ** 2)\n",
    "\n",
    "\n",
    "# Calculate the total log-likelihood of the univariate volatility\n",
    "def total_univariate_log_likelihood(GARCH_guess, x):\n",
    "    # Set Number of Observations\n",
    "    T = len(x)\n",
    "    \n",
    "    # Set Parameters\n",
    "    omega, alpha, beta = GARCH_guess\n",
    "    sigma = np.zeros(T)\n",
    "\n",
    "    # Set the Initial Sigma to be Total Unconditional Variance of data\n",
    "    sigma[0] = np.sqrt(np.var(x))\n",
    "\n",
    "    # Calculate sigma[t] for the described model\n",
    "    for t in range(1, T):\n",
    "        sigma[t] = omega + alpha * np.abs(x[t-1]) + beta * np.abs(sigma[t-1])\n",
    "\n",
    "    # Calculate the sum of the Log-Likelihood contributions\n",
    "    univariate_log_likelihood = sum(univariate_log_likelihood_contribution(x[t], sigma[t]) for t in range(T))\n",
    "\n",
    "    # Return the Negative Log-Likelihood\n",
    "    return -univariate_log_likelihood\n",
    "\n",
    "\n",
    "\n",
    "# Minimize - total log-likelihood of the univariate volatility\n",
    "def estimate_univariate_models(x):\n",
    "    # Initial Guess for omega, alpha, beta\n",
    "    GARCH_guess = [0.002, 0.2, 0.7]\n",
    "\n",
    "    # Minimize the Negative Log-Likelihood Function\n",
    "    result = minimize(fun=total_univariate_log_likelihood, x0=GARCH_guess, args=(x,), bounds=[(0, None), (0, 1), (0, 1)])\n",
    "    #print(f\"Estimated parameters: omega = {result.x[0]}, alpha = {result.x[1]}, beta = {result.x[2]}\")\n",
    "\n",
    "    # Set Parameters\n",
    "    result_parameters = result.x\n",
    "\n",
    "    # Set Variance-Covariance Hessian\n",
    "    result_hessian = result.hess_inv.todense()  \n",
    "\n",
    "    # Set Standard Errors\n",
    "    result_se = np.sqrt(np.diagonal(result_hessian))\n",
    "\n",
    "\n",
    "    # Return Parameters and Information\n",
    "    return result_parameters, result_hessian, result_se\n",
    "\n",
    "# Get an array of univariate model parameters for all timeseries\n",
    "def estimate_univariate_parameters(data, labels):\n",
    "    # Create list to store univariate parameters, hessians, and standard errors\n",
    "    univariate_parameters = []\n",
    "    # univariate_hessians = []\n",
    "    # univariate_standard_errors = []\n",
    "\n",
    "    # Iterate over each time series in 'data' and estimate parameters\n",
    "    for i in range(data.shape[0]):  # data.shape[1] gives the number of time series (columns) in 'data'\n",
    "        result_parameters, result_hessian, result_se = estimate_univariate_models(data[:, i])\n",
    "        univariate_parameters.append(result_parameters)\n",
    "        # univariate_hessians.append(result_hessian)\n",
    "        # univariate_standard_errors.append(result_se)\n",
    "        # Print the label and the estimated parameters for each time series\n",
    "        print(f\"Time Series: {labels[i]}, \\n    Estimated parameters: \\n \\t omega = {result_parameters[0]}, \\n \\t alpha = {result_parameters[1]}, \\n \\t beta = {result_parameters[2]}\")\n",
    "    # Convert the lists of results to numpy arrayst \n",
    "    univariate_parameters_array = np.array(univariate_parameters)\n",
    "    # univariate_hessians_array = np.array(univariate_hessians)\n",
    "    # univariate_standard_errors_array = np.array(univariate_standard_errors)\n",
    "\n",
    "    # Return the results\n",
    "    return univariate_parameters_array# univariate_hessians_array, univariate_standard_errors_array\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f5c4b9-375e-4088-a398-094d78c30d9a",
   "metadata": {},
   "source": [
    "# Prepare Data, and Univariate Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fabf39b-b044-471f-a90b-b3d942045fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00197239  0.00197239 -0.00197239 ... -0.00316556  0.00042265\n",
      "   0.        ]\n",
      " [ 0.00096759  0.          0.00048344 ... -0.0006003  -0.00160256\n",
      "   0.        ]\n",
      " [ 0.         -0.0035524  -0.00035594 ...  0.         -0.00150319\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.00160227  0.00479146  0.00036762 ...  0.00265135 -0.00035311\n",
      "  -0.00070659]\n",
      " [-0.00135196  0.00236473  0.00448884 ...  0.00433437 -0.0049551\n",
      "  -0.00435595]\n",
      " [-0.00740727  0.01469052  0.01129643 ...  0.00794236 -0.00189219\n",
      "  -0.00113291]]\n",
      "Time Series: MajInv Dk Obl, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0008637725976579379, \n",
      " \t alpha = 0.0, \n",
      " \t beta = 0.74042270514206\n",
      "Time Series: MajInv Gl Obl, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 0.2600653192868514, \n",
      " \t beta = 0.9102183011529178\n",
      "Time Series: SparInv Stab Obl, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 0.19380320433138407, \n",
      " \t beta = 0.9560796309145296\n",
      "Time Series: BankInv Korte Obl, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 0.24456351861332107, \n",
      " \t beta = 0.8559031981520634\n",
      "Time Series: DI Dk Ind, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 0.9283729165851419, \n",
      " \t beta = 0.42077080481307866\n",
      "Time Series: Xact OMX C25, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 1.0, \n",
      " \t beta = 0.5851192959323556\n",
      "Time Series: MSCI World, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0021517606705595987, \n",
      " \t alpha = 0.0, \n",
      " \t beta = 4.673727143902554e-07\n",
      "Time Series: MSCI ACWI, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0012807453184365046, \n",
      " \t alpha = 0.0, \n",
      " \t beta = 0.7354699099408649\n",
      "Time Series: MSCI Min. Vol, \n",
      "    Estimated parameters: \n",
      " \t omega = 8.348099534213354e-05, \n",
      " \t alpha = 1.0, \n",
      " \t beta = 0.6744051784610778\n",
      "Time Series: MSCI Small Cap, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0004925341458036909, \n",
      " \t alpha = 0.24359619514581382, \n",
      " \t beta = 0.8159909421750137\n",
      "Time Series: MSCI EM, \n",
      "    Estimated parameters: \n",
      " \t omega = 0.0, \n",
      " \t alpha = 0.2796284691934503, \n",
      " \t beta = 0.8966610957382604\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[8.63772598e-04, 0.00000000e+00, 7.40422705e-01],\n",
       "       [0.00000000e+00, 2.60065319e-01, 9.10218301e-01],\n",
       "       [0.00000000e+00, 1.93803204e-01, 9.56079631e-01],\n",
       "       [0.00000000e+00, 2.44563519e-01, 8.55903198e-01],\n",
       "       [0.00000000e+00, 9.28372917e-01, 4.20770805e-01],\n",
       "       [0.00000000e+00, 1.00000000e+00, 5.85119296e-01],\n",
       "       [2.15176067e-03, 0.00000000e+00, 4.67372714e-07],\n",
       "       [1.28074532e-03, 0.00000000e+00, 7.35469910e-01],\n",
       "       [8.34809953e-05, 1.00000000e+00, 6.74405178e-01],\n",
       "       [4.92534146e-04, 2.43596195e-01, 8.15990942e-01],\n",
       "       [0.00000000e+00, 2.79628469e-01, 8.96661096e-01]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('11.csv')\n",
    "\n",
    "data, labels = df_to_array(df)\n",
    "print(data)\n",
    "N, T= data.shape\n",
    "# Estimate Univariate Parameters\n",
    "univ_params = estimate_univariate_parameters(data, labels)\n",
    "N,T\n",
    "univ_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee618f31-b558-4e5b-94b5-f1954a67c08a",
   "metadata": {},
   "source": [
    "# Setup of functions for estimation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74979170-5a0b-4890-ac9e-8d06c04b9882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forms the Correlation Matrix from RSDC_correlation_guess\n",
    "def form_correlation_matrix(multi_guess):\n",
    "    # Determine the size of the matrix\n",
    "    n = int(np.sqrt(len(multi_guess) * 2)) + 1\n",
    "    if len(multi_guess) != n*(n-1)//2:\n",
    "        raise ValueError(\"Invalid number of parameters for any symmetric matrix.\")\n",
    "    \n",
    "    # Create an identity matrix of size n\n",
    "    matrix = np.eye(n)\n",
    "    \n",
    "    # Fill in the off-diagonal elements\n",
    "    param_index = 0\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            matrix[i, j] = matrix[j, i] = multi_guess[param_index]\n",
    "            param_index += 1\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "\n",
    "# Calculate the Standard Deviations, sigma, from Univariate Estimates\n",
    "    # This could be done outside of the objective function? \n",
    "def calculate_standard_deviations(data, univariate_estimates):\n",
    "    # Get Data Dimensions\n",
    "    N,T = data.shape\n",
    "\n",
    "    # Create Array for Standard Deviations\n",
    "    standard_deviations = np.zeros((T,N))\n",
    "\n",
    "    # Calculate Sigmas for each timeseries\n",
    "    for i in range(N):\n",
    "        # Unpack Univariate Estimates\n",
    "        omega, alpha, beta = univariate_estimates[i]\n",
    "\n",
    "        # Create array for Sigma values\n",
    "        sigma = np.zeros(T)\n",
    "\n",
    "        # Set first observation of Sigma to Sample Variance\n",
    "        sigma[0] = np.sqrt(np.var(data[:, i]))\n",
    "\n",
    "        # Calculate Sigma[t]\n",
    "        for t in range(1, T):\n",
    "            sigma[t] = omega + alpha * np.abs(data[i,t-1]) + beta * np.abs(sigma[t-1])\n",
    "\n",
    "        # Save Sigmas to Standard Deviation Array\n",
    "        standard_deviations[:, i] = sigma\n",
    "\n",
    "    # Return array of all Standard Deviations\n",
    "    return standard_deviations\n",
    "\n",
    "\n",
    "# Creates a Diagonal Matrix of (N x N), with Standard Deviations on Diagonal, and zeros off the Diagonal\n",
    "def create_diagonal_matrix(t, std_array):\n",
    "    \"\"\"\n",
    "    Creates an N x N diagonal matrix with standard deviations at time t on the diagonal,\n",
    "    and zeros elsewhere. Here, N is the number of time series.\n",
    "\n",
    "    :param t: Integer, the time index for which the diagonal matrix is created.\n",
    "    :param standard_deviations: List of numpy arrays, each array contains the standard deviations over time for a variable.\n",
    "    :return: Numpy array, an N x N diagonal matrix with the standard deviations at time t on the diagonal.\n",
    "    \"\"\"\n",
    "    # Extract the standard deviations at time t for each series\n",
    "    stds_at_t = np.array(std_array[t,:])\n",
    "    \n",
    "    # Create a diagonal matrix with these values\n",
    "    diagonal_matrix = np.diag(stds_at_t)\n",
    "    \n",
    "    return diagonal_matrix\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Check if a Correlation Matrix is PSD, Elements in [-1,1], and symmetric.\n",
    "def check_correlation_matrix_is_valid(correlation_matrix):\n",
    "    # Check diagonal elements are all 1\n",
    "    if not np.all(np.diag(correlation_matrix) == 1):\n",
    "        return False, \"Not all diagonal elements are 1.\"\n",
    "    \n",
    "    # Check off-diagonal elements are between -1 and 1\n",
    "    if not np.all((correlation_matrix >= -1) & (correlation_matrix <= 1)):\n",
    "        return False, \"Not all off-diagonal elements are between -1 and 1.\"\n",
    "    \n",
    "    # Check if the matrix is positive semi-definite\n",
    "    # A matrix is positive semi-definite if all its eigenvalues are non-negative.\n",
    "    eigenvalues = np.linalg.eigvals(correlation_matrix)\n",
    "    if np.any(eigenvalues < -0.5):\n",
    "        print(eigenvalues)\n",
    "        return False, \"The matrix is not positive semi-definite.\"\n",
    "    \n",
    "    return True, \"The matrix meets all criteria.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c4710a5-f5c6-4cfc-a8a8-f85b8db878d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc191cb5-0c23-47c1-9f84-c6934a84c255",
   "metadata": {},
   "source": [
    "# The Likelihood Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4de8b4da-03e7-4aaa-9556-02509d1a2a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ccc_likelihood_contribution(t, data, R, standard_deviations):\n",
    "    # What we need in the terms:\n",
    "    data = data.T\n",
    "    D = create_diagonal_matrix(t, standard_deviations)\n",
    "    # R is defined in Total CCC Likelihood \n",
    "    \n",
    "\n",
    "    # Linear Algebra\n",
    "    det_D = np.linalg.det(D)\n",
    "    inv_D = np.linalg.inv(D)\n",
    "    det_R = np.linalg.det(R)\n",
    "    inv_R = np.linalg.inv(R)\n",
    "\n",
    "    # The Shock Term\n",
    "    z = inv_D @ data[t]\n",
    "\n",
    "    # The Terms of the Log Likelihood Contribution\n",
    "    term_1 = N * np.log(2 * np.pi)\n",
    "    term_2 = 2 * np.log(det_D) \n",
    "    term_3 = np.log(det_R)\n",
    "    term_4 = z.T @ inv_R @ z\n",
    "\n",
    "    log_likelihood_contribution = -0.5 * (term_1 + term_2 + term_3 + term_4)\n",
    "    return log_likelihood_contribution\n",
    "\n",
    "def Hamilton_Filter(data,random_guesses, standard_deviations):\n",
    "    # Get Shape of Data\n",
    "    N, T = data.shape\n",
    "\n",
    "    # Form the Correlation Matrix\n",
    "    R = form_correlation_matrix(random_guesses)\n",
    "    # Array for Log-Likelihoods Contributions\n",
    "    log_likelihood_contributions = np.zeros(T)\n",
    "\n",
    "    # The For Loop\n",
    "    for t in range(T):\n",
    "        log_likelihood_contributions[t] = ccc_likelihood_contribution(t, data, R, standard_deviations)\n",
    "\n",
    "    negative_likelihood = - np.sum(log_likelihood_contributions)\n",
    "    #print(negative_likelihood)\n",
    "    # Return Negative Likelihood\n",
    "    return negative_likelihood   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac09d98-c2d6-4882-bd91-f63acff96edf",
   "metadata": {},
   "source": [
    "# Minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26dcc5b6-8f32-42f3-a5f7-3d6f428e3dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(data):\n",
    "    number_of_correlation_parameters = N * (N - 1) / 2\n",
    "    \n",
    "    random_guesses = np.random.uniform(-0.5, 0.5, int(number_of_correlation_parameters)).tolist()\n",
    "    m_bounds = []\n",
    "    m_bounds += [(-0.99, 0.99)] * int(number_of_correlation_parameters)\n",
    "\n",
    "    print(random_guesses)\n",
    "    standard_deviations = np.zeros((N,T))\n",
    "    \n",
    "    standard_deviations = calculate_standard_deviations(data, univ_params)\n",
    "    def objective_function(random_guesses):\n",
    "        return Hamilton_Filter(data,random_guesses, standard_deviations)\n",
    "    result = minimize(objective_function, random_guesses, bounds=m_bounds, method='L-BFGS-B')\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5231d219-8760-46af-ab1e-94564937abb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.3046334467607793, 0.16203730150161932, 0.17122434783375529, -0.10915401020770799, 0.2607391870127772, 0.3814486434986283, 0.3614001081582049, 0.4221618691275266, 0.037478421841800835, 0.47350640566468705, 0.2037582263980059, -0.3041292727372156, 0.04559447780082071, -0.17444284822316003, 0.4885593765941352, -0.34753381152820817, 0.0026706762678782026, -0.47928991014682343, -0.21579838227663262, -0.4435478499942074, 0.4450578508210399, 0.4779149870600866, 0.4493997781806832, -0.06873940784793431, -0.40892642304996907, 0.4198256557727883, -0.32821989469317425, 0.2997575654789113, 0.34666720281999885, 0.05086417101971308, 0.24694463071555417, 0.49835717857016715, 0.04160869825985347, -0.23962017875412644, -0.12687222413925991, -0.4178875877860093, 0.003878886141184368, 0.40685613706385937, 0.41242968141314384, -0.01296852295559281, -0.3224349799559585, -0.415657731848991, -0.29919117162455267, 0.4646457993434331, -0.18896194546805634, 0.2358171683766257, -0.36082235101194693, 0.28984509162874006, -0.1380755654388366, 0.36794532525869406, -0.1520125623166364, -0.4253784880225755, -0.3867889173283494, -0.012838355911411914, -0.2589488294438185]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_597739/3966505891.py:20: RuntimeWarning: invalid value encountered in log\n",
      "  term_3 = np.log(det_R)\n",
      "/home/august/.venvs/jupyter/lib/python3.11/site-packages/numpy/linalg/linalg.py:2180: RuntimeWarning: invalid value encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    }
   ],
   "source": [
    "fitted = fit(data)\n",
    "fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c178e26-f1d7-44ba-9e88-827f524a2508",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_matrix = form_correlation_matrix(fitted.x)\n",
    "result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d2b31b-a761-4234-8758-ad01ddaeec71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heatmaps(df, result_matrix, labels):\n",
    "    # Calculate the correlation matrix for the DataFrame\n",
    "    corr_matrix = df.corr()\n",
    "    dims, dimz = result_matrix.shape\n",
    "    print(dims)\n",
    "    # Set up the matplotlib figure with subplots\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    \n",
    "    # Plot the Unconditional Correlation heatmap\n",
    "    sns.heatmap(corr_matrix, ax=ax[0], annot=True, cmap='coolwarm')\n",
    "    ax[0].set_title('Unconditional Correlation')\n",
    "    \n",
    "    # Plot the Conditional Correlation heatmap\n",
    "    sns.heatmap(result_matrix, ax=ax[1], annot=True, cmap='coolwarm', xticklabels=labels, yticklabels=labels)\n",
    "    ax[1].set_title('Conditional Correlation')\n",
    "    \n",
    "    # Adjust layout for better appearance\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save the figure\n",
    "    plt.savefig(f'Heatmaps {dims}.png')\n",
    "    \n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage (note: you need to have a DataFrame `df` and a `result_matrix` variable ready for this to work):\n",
    "# plot_side_by_side_heatmaps(df, result_matrix, labels)\n",
    "\n",
    "# This function assumes you have a DataFrame `df`, a result matrix `result_matrix`, and a list of labels `labels`.\n",
    "# Replace 'df', 'result_matrix', and 'labels' with your actual data variables when using this function.\n",
    "plot_heatmaps(df, result_matrix, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e7e955-4a91-48f7-937b-d89be69ef779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
