{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8494778-4f8d-4843-8c55-b9738f0c00e6",
   "metadata": {},
   "source": [
    "# The Hamilton Filter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10e9bb92-92ac-4d08-bb61-2806a9d9bc31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1437"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing packages we need\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt #pyplot is used to plot the data\n",
    "import scipy.optimize as opt #used to numerically optimize\n",
    "from datetime import time, timedelta, datetime\n",
    "import yfinance as yf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "data=np.genfromtxt('SP500.csv', delimiter=',',usecols=np.arange(0,4)) #loading in first 4 columns\n",
    "y = data[15097:, 3:4]*100 # 100 times log-returns of the S&P 500 index. January 4, 2010 - till end\n",
    "y=y.T[0,:] #unpacking numpy array\n",
    "T = len(y) #length of time series\n",
    "# data = data['SP500 - Log-Return']\n",
    "\n",
    "# Plot the transformed data\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(data)\n",
    "# plt.title(f'Log-Differenced Close Prices for {ticker}')\n",
    "# plt.xlabel('Date')\n",
    "# plt.ylabel('Log-Differenced Prices')\n",
    "# plt.show()\n",
    "data = y\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb63337-26d7-40e9-8b03-1e6d01041cee",
   "metadata": {},
   "source": [
    "# The Steps of the Algorithm\n",
    "### The distribution of $x_t$ is given by\n",
    "$$f(x_t|X_{0:t-1})=\\sum_{i=1}^Nf(x_t|s_t=i)P(s_t=i|X_{0:t-1})$$\n",
    "\n",
    "### The likeliood contribution\n",
    "$$f(x_t|x_{t=1}, s_t=i) = \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}}\\exp\\left\\{-\\frac{y^2}{2 \\sigma_i^2}\\right\\}$$\n",
    "\n",
    "### The Predicition Step:\n",
    "$$P(s_t=i|X_{0:t-1})=\\sum_{j=i}^Np_{ji} P(s_{t-1}=j|X_{0:t-1})$$\n",
    "\n",
    "### The Filtering Step:\n",
    "$$P(s_t=i|X_{0:t})=\\frac{f(x_t|s_t=i)P(s_t=i|X_{0:t-1})}{\\sum_{j=1}^Nf(x_t|s_t=j)P(s_t=j|X_{0:t-1})}$$\n",
    "\n",
    "\n",
    "### The Smoothing Step:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5638a21e-7128-46d2-b27d-3ec55e62eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data=np.genfromtxt('SP_500.csv', delimiter=',',usecols=np.arange(0,4)) #loading in first 4 columns\n",
    "# y = data[15097:, 3:4]*100 # 100 times log-returns of the S&P 500 index. January 4, 2010 - till end\n",
    "# y=y.T[0,:] #unpacking numpy array\n",
    "# T = len(y) #length of time series\n",
    "# data = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5b8d29-c8da-4827-982e-564dbefdcfa9",
   "metadata": {},
   "source": [
    "# New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4272ffc-25f9-48d2-932c-d50ef94e87e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.59160816  0.31108326  0.05453718 ...  1.27496879  0.86677408\n",
      " -0.25643447]\n"
     ]
    }
   ],
   "source": [
    "n_states=2\n",
    "print(data)\n",
    "def parameterize(params):\n",
    "    \"\"\"\n",
    "    takes parameters,\n",
    "    creates: \n",
    "        p_00, p_11\n",
    "        the sigmas   \n",
    "\n",
    "    ! This is not expanded to fit n_states!   \n",
    "    \"\"\"\n",
    "    p_00 = params[0]\n",
    "    p_11 = params[1]\n",
    "    sigma = params[2:4];\n",
    "    mu = params[4:6];\n",
    "    phi = params[6:8];\n",
    "    \n",
    "    return p_00, p_11, sigma, mu, phi\n",
    "\n",
    "def create_transition_matrix(p_00, p_11):\n",
    "    \"\"\"\n",
    "    Create the Transition Matrix \n",
    "\n",
    "    ! This is not expanded to fit n_states!\n",
    "    \"\"\"\n",
    "    transition_matrix = np.zeros([2, 2])\n",
    "    transition_matrix[0] = p_00, 1 - p_11\n",
    "    transition_matrix[1] = 1 - p_00, p_11\n",
    "    return transition_matrix.T\n",
    "\n",
    "def calculate_initial_probabilities(transition_matrix):\n",
    "    \"\"\"\n",
    "    Use linalg to find the initial probabilities:\n",
    "\n",
    "    ! This is not expanded to fit n_states!\n",
    "    \"\"\"\n",
    "    A_matrix = np.vstack(((np.identity(2)- transition_matrix), np.ones([1,2])))\n",
    "    pi_first = np.linalg.inv(A_matrix.T.dot(A_matrix)).dot(A_matrix.T)\n",
    "    pi_second = np.vstack((np.zeros([2,1]), np.ones([1,1])))\n",
    "    initial_probs = pi_first.dot(pi_second)\n",
    "    initial_probabilities = initial_probs.T\n",
    "    return initial_probabilities\n",
    "\n",
    "def density_function(t, state,sigma, mu, phi):\n",
    "    # return -0.5 * np.log(2 * np.pi) - 0.5 * np.log(sigma[state]) - 0.5 * ((data[t] - mu[state] - phi[state] * data[t-1]) ** 2) / sigma[state] \n",
    "    return np.exp(-0.5 * np.log(2 * np.pi) - 0.5 * np.log(sigma[state]) - 0.5 * ((data[t] - mu[state] - phi[state] * data[t-1]) ** 2) / sigma[state])\n",
    "\n",
    "\n",
    "def prediction_step(transition_matrix, filtered_probabilities, t):\n",
    "    \"\"\"\n",
    "    Use the dot product of the transition_matrix and the filtered_probability\n",
    "    \"\"\"  \n",
    "    predictions = transition_matrix.dot(filtered_probabilities[:,t])\n",
    "    return predictions\n",
    "\n",
    "def filtering_step(partial_likelihood, likelihood_contributions, t):\n",
    "    \"\"\"\n",
    "    For State in n_states\n",
    "        Set filtered_pribabilities for a stateequal to partial_likelihood for the state divided by total likelihood.\n",
    "    \"\"\"\n",
    "    filtered = np.zeros(n_states)\n",
    "    for state in range(n_states):\n",
    "        filtered[state] = partial_likelihood[state] / likelihood_contributions[t]\n",
    "    return filtered\n",
    "\n",
    "def objective(initial_guess):\n",
    "    \"\"\"\n",
    "    Setup Arrays for Book Keeping\n",
    "    Create Parameters\n",
    "    for t in rainge(num_obs):\n",
    "        ...\n",
    "    \"\"\"\n",
    "    n_states = 2\n",
    "    # For Book Keeping\n",
    "    num_obs = len(data)\n",
    "    predicted_probabilities = np.zeros([n_states, num_obs+1])\n",
    "    filtered_probabilities = np.zeros([n_states, num_obs])\n",
    "    smoothed_probabilities = np.zeros([n_states, num_obs])\n",
    "    likelihood_contributions = np.zeros(num_obs)\n",
    "\n",
    "\n",
    "    # Form Model Parameters\n",
    "    p_00, p_11, sigma, mu, phi = parameterize(initial_guess)\n",
    "\n",
    "    # Form Transition Matrix\n",
    "    transition_matrix = create_transition_matrix(p_00, p_11)\n",
    "\n",
    "    # Form Initial Probabilities\n",
    "    predicted_probabilities[[0,1],0] = calculate_initial_probabilities(transition_matrix)\n",
    "\n",
    "    # To Hold values of Forward Filter Recursions\n",
    "    eta = np.zeros(n_states)\n",
    "    \n",
    "    # To Hold values of Forward Filter Recursions\n",
    "    filters = np.zeros(n_states)\n",
    "    \n",
    "    # To Hold values of Partial Log-Likelihoods.\n",
    "    partial_likelihood = np.zeros(n_states)\n",
    "\n",
    "    # The Main For Loop:\n",
    "    for t in range(num_obs):\n",
    "        # Calculate State Densities\n",
    "        for state in range(n_states):\n",
    "            eta[state] = density_function(t, state, sigma, mu, phi)\n",
    "            partial_likelihood[state] = predicted_probabilities[state,t] * eta[state]\n",
    "\n",
    "        # Calculate the Log-Likelihood\n",
    "\n",
    "        likelihood_contributions[t] = np.log(np.sum(partial_likelihood))\n",
    "\n",
    "        # Calculate the Filtering Step\n",
    "        num0 = eta[0] * predicted_probabilities[0,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "        num1 = eta[1] * predicted_probabilities[1,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "        filtered_probabilities[[0,1],t] = num0, num1\n",
    "        # filtered_probabilities[:,t] = filtering_step(partial_likelihood, likelihood_contributions, t)\n",
    "\n",
    "        # Calculate the Prediction step\n",
    "        predicted_probabilities[[0,1],t+1] = transition_matrix.dot(filtered_probabilities[[0,1],t])\n",
    "        #predicted_probabilities[:, t+1] = prediction_step(transition_matrix, filtered_probabilities, t)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # print(f' Likelihood Value :  {likelihood_contributions[t]}')\n",
    "        # print(f'  Predicted Probability:  {predicted_probabilities[:, t+1]}')\n",
    "        # print(f' Filtered Probability :  {filtered_probabilities[:,t] }')\n",
    "        # print(f'Eta  :  {eta}')\n",
    "        # print(f'Partial Likelihood  :  {partial_likelihood}')\n",
    "    # Return the Negative Sum of the Log-Likelihood\n",
    "    \n",
    "    negative_likelihood = -np.sum(likelihood_contributions)\n",
    "\n",
    "    return negative_likelihood\n",
    "    \n",
    "def fit(data):\n",
    "    \"\"\"\n",
    "    Minimize the objective Function\n",
    "        Use initial Guess, constraints, bounds, and arguments.\n",
    "        Print results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initial Guesses\n",
    "    variance = np.var(data)\n",
    "    initial_guess= np.array([0.9, 0.9, np.sqrt(2*variance), np.sqrt(0.5*variance),0,0,0,0])\n",
    "\n",
    "    # Parameter Bounds\n",
    "    my_bounds = bounds=((0.001,0.9999),(0.001,0.9999),(0.01,None),(0.01,None),(None,None),(None,None),(None,None),(None,None))\n",
    "\n",
    "    # Missing: Constraint, args \n",
    "\n",
    "\n",
    "    res = minimize(objective, initial_guess, method='L-BFGS-B', bounds=my_bounds) # constraint=cons,arg=args)\n",
    "\n",
    "    # Hessian, standard errors, print etc\n",
    "    res.x\n",
    "    print(res.nit)\n",
    "    v_hessian = res.hess_inv.todense()\n",
    "    se_hessian = np.sqrt(np.diagonal(v_hessian))\n",
    "\n",
    "    # The Results:\n",
    "    estimated_parameters = res.x\n",
    "    se = se_hessian\n",
    "    print('P11='+str(estimated_parameters[0])+', std.errors='+str(se[0]))\n",
    "    print('P22='+str(estimated_parameters[1])+', std.errors='+str(se[1]))\n",
    "    print('h1='+str(estimated_parameters[2])+', std.errors='+str(se[2]))\n",
    "    print('h2='+str(estimated_parameters[3])+', std.errors='+str(se[3]))\n",
    "    print('mu1='+str(estimated_parameters[4])+', std.errors='+str(se[4]))\n",
    "    print('mu2='+str(estimated_parameters[5])+', std.errors='+str(se[5]))\n",
    "    print('phi='+str(estimated_parameters[6])+', std.errors='+str(se[6]))\n",
    "    print('phi2='+str(estimated_parameters[7])+', std.errors='+str(se[7]))\n",
    "\n",
    "    return estimated_parameters\n",
    "\n",
    "def smoothed(estimates):\n",
    "    \"\"\"\n",
    "        ...\n",
    "    \"\"\"\n",
    "    # For Book Keeping\n",
    "    num_obs = len(data)\n",
    "    predicted_probabilities = np.zeros([n_states, num_obs+1])\n",
    "    filtered_probabilities = np.zeros([n_states, num_obs])\n",
    "    smoothed_probabilities = np.zeros([n_states, num_obs])\n",
    "    likelihood_contributions = np.zeros(num_obs)\n",
    "\n",
    "\n",
    "    # Form Model Parameters\n",
    "    p_00, p_11, sigma, mu, phi = parameterize(estimates)\n",
    "\n",
    "    # Form Transition Matrix\n",
    "    transition_matrix = create_transition_matrix(p_00, p_11)\n",
    "\n",
    "    # Form Initial Probabilities\n",
    "    predicted_probabilities[[0,1],0] = calculate_initial_probabilities(transition_matrix)\n",
    "\n",
    "    # To Hold values of Forward Filter Recursions\n",
    "    eta = np.zeros(n_states)\n",
    "    \n",
    "    # To Hold values of Forward Filter Recursions\n",
    "    filters = np.zeros(n_states)\n",
    "    \n",
    "    # To Hold values of Partial Log-Likelihoods.\n",
    "    partial_likelihood = np.zeros(n_states)\n",
    "    filtered_volatility = np.zeros(num_obs)\n",
    "    # The Main For Loop:\n",
    "    for t in range(num_obs):\n",
    "        # Calculate State Densities\n",
    "        for state in range(n_states):\n",
    "            eta[state] = density_function(t, state, sigma, mu, phi)\n",
    "            partial_likelihood[state] = predicted_probabilities[state,t] * eta[state]\n",
    "\n",
    "        # Calculate the Log-Likelihood\n",
    "\n",
    "        likelihood_contributions[t] = np.log(np.sum(partial_likelihood))\n",
    "\n",
    "        # Calculate the Filtering Step\n",
    "        num0 = eta[0] * predicted_probabilities[0,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "        num1 = eta[1] * predicted_probabilities[1,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "        filtered_probabilities[[0,1],t] = num0, num1\n",
    "        # filtered_probabilities[:,t] = filtering_step(partial_likelihood, likelihood_contributions, t)\n",
    "\n",
    "        # Calculate the Prediction step\n",
    "        predicted_probabilities[[0,1],t+1] = transition_matrix.dot(filtered_probabilities[[0,1],t])\n",
    "        #predicted_probabilities[:, t+1] = prediction_step(transition_matrix, filtered_probabilities, t)\n",
    "        \n",
    "\n",
    "        filtered_volatility[t] = filtered_probabilities[[0],t] * sigma[0] + (1 - filtered_probabilities[[0],t] * sigma[1])\n",
    "        # Backwards Smoother\n",
    "        smoothed_probabilities[:,num_obs-1]=filtered_probabilities[:,num_obs-1]\n",
    "        for t in range(num_obs-2, 0, -1):\n",
    "            smoothed_probabilities[:,t] = filtered_probabilities[:,t] * (transition_matrix.T.dot(smoothed_probabilities[:,t+1] / predicted_probabilities[:,t+1]))\n",
    "\n",
    "\n",
    "        # print(f' Likelihood Value :  {likelihood_contributions[t]}')\n",
    "        # print(f'  Predicted Probability:  {predicted_probabilities[:, t+1]}')\n",
    "        # print(f' Filtered Probability :  {filtered_probabilities[:,t] }')\n",
    "        # print(f'Eta  :  {eta}')\n",
    "        # print(f'Partial Likelihood  :  {partial_likelihood}')\n",
    "    # Return the Negative Sum of the Log-Likelihood\n",
    "    return predicted_probabilities, filtered_probabilities, smoothed_probabilities, filtered_volatility\n",
    "\n",
    "\n",
    "def plot_my_data(data, filtered_volatility):\n",
    "    fig, ax=plt.subplots(2, figsize=(14,7))\n",
    "    #fig.set_figheight=(9)\n",
    "    #fig.set_figwidth=(16)\n",
    "    fig.suptitle('log-return and filtered volatility')\n",
    "    ax[0].plot(data,color='r')\n",
    "    ax[1].plot(np.sqrt(filtered_volatility))\n",
    "\n",
    "    #Setting titles\n",
    "    ax[0].title.set_text('Log-returns, $x_t$')\n",
    "    ax[1].title.set_text('Filtered volatility, $E[\\sigma_t|x_t,x_{t-1},...,x_1]$')\n",
    "\n",
    "def plot_my_probabilities(data, predicted_probabilities, filtered_probabilities, smoothed_probabilities):\n",
    "    num_obs = len(data)\n",
    "\n",
    "    #Predicted state probability, Filtered state probability and smoothed state probability\n",
    "    fig, ax=plt.subplots(3, figsize=(16,9))\n",
    "    #fig.tight_layout() \n",
    "\n",
    "    #Adjusting size between subplots\n",
    "    fig.subplots_adjust(left=None, bottom=0.025, right=None, top=None, wspace=None, hspace=None)\n",
    "    #default\n",
    "    #left  = 0.125  # the left side of the subplots of the figure\n",
    "    #right = 0.9    # the right side of the subplots of the figure\n",
    "    #bottom = 0.1   # the bottom of the subplots of the figure\n",
    "    #top = 0.9      # the top of the subplots of the figure\n",
    "    #wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "    #hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "\n",
    "\n",
    "    ax[0].plot(1 - predicted_probabilities[0,:])\n",
    "    ax[1].plot(1 - filtered_probabilities[0,:])\n",
    "    ax[2].plot(1 - smoothed_probabilities[0,:])\n",
    "\n",
    "    #Setting limits on x axis\n",
    "    ax[0].set_xlim(0, num_obs)\n",
    "    ax[1].set_xlim(0, num_obs)\n",
    "    ax[2].set_xlim(0, num_obs)\n",
    "\n",
    "    #Setting titles\n",
    "    ax[0].title.set_text('Predicted state probability, $P(s_t=1|x_{t-1},x_{t-2},...,x_{1})$')\n",
    "    ax[1].title.set_text('Filtered state probability, $P(s_t=1|x_{t},x_{t-1},...,x_{1})$')\n",
    "    ax[2].title.set_text('Smoothed state probability, $P(s_t=1|x_{T},x_{T-1},...,x_{1})$')\n",
    "\n",
    "    #Setting lines at 0 and 1\n",
    "    ax[0].axhline(0,color='black', linestyle=\"--\")\n",
    "    ax[0].axhline(1,color='black', linestyle=\"--\")\n",
    "\n",
    "    ax[1].axhline(0,color='black', linestyle=\"--\")\n",
    "    ax[1].axhline(1,color='black', linestyle=\"--\")\n",
    "\n",
    "    ax[2].axhline(0,color='black', linestyle=\"--\")\n",
    "    ax[2].axhline(1,color='black', linestyle=\"--\")\n",
    "\n",
    "my_fitted = fit(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aeaafbf-7f94-431b-9372-b260a47fcc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probabilities, filtered_probabilities, smoothed_probabilities, filtered_volatility = smoothed(my_fitted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de80a397-80cd-45eb-b160-bf6da0bbe7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_my_data(data, filtered_volatility)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d89a8f2-11ef-42c7-9bab-65e925256fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_my_probabilities(data, predicted_probabilities, filtered_probabilities, smoothed_probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bc76a6-85ed-45f3-8f3a-3cc551c8ad9e",
   "metadata": {},
   "source": [
    "# Backup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5402cf47-2456-41a8-b564-218fef823120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# n_states=2\n",
    "# print(data)\n",
    "# def parameterize(params):\n",
    "#     \"\"\"\n",
    "#     takes parameters,\n",
    "#     creates: \n",
    "#         p_00, p_11\n",
    "#         the sigmas   \n",
    "\n",
    "#     ! This is not expanded to fit n_states!   \n",
    "#     \"\"\"\n",
    "#     p_00 = params[0]\n",
    "#     p_11 = params[1]\n",
    "#     sigma = params[2:4];\n",
    "#     mu = params[4:6];\n",
    "#     phi = params[6:8];\n",
    "    \n",
    "#     return p_00, p_11, sigma, mu, phi\n",
    "\n",
    "# def create_transition_matrix(p_00, p_11):\n",
    "#     \"\"\"\n",
    "#     Create the Transition Matrix \n",
    "\n",
    "#     ! This is not expanded to fit n_states!\n",
    "#     \"\"\"\n",
    "#     transition_matrix = np.zeros([2, 2])\n",
    "#     transition_matrix[0] = p_00, 1 - p_11\n",
    "#     transition_matrix[1] = 1 - p_00, p_11\n",
    "#     return transition_matrix\n",
    "\n",
    "# def calculate_initial_probabilities(transition_matrix):\n",
    "#     \"\"\"\n",
    "#     Use linalg to find the initial probabilities:\n",
    "\n",
    "#     ! This is not expanded to fit n_states!\n",
    "#     \"\"\"\n",
    "#     A_matrix = np.vstack(((np.identity(2)- transition_matrix), np.ones([1,2])))\n",
    "#     pi_first = np.linalg.inv(A_matrix.T.dot(A_matrix)).dot(A_matrix.T)\n",
    "#     pi_second = np.vstack((np.zeros([2,1]), np.ones([1,1])))\n",
    "#     initial_probs = pi_first.dot(pi_second)\n",
    "#     initial_probabilities = initial_probs.T\n",
    "#     return initial_probabilities\n",
    "\n",
    "# def density_function(t, state,sigma, mu, phi):\n",
    "#     return np.exp(-0.5 * np.log(2 * np.pi) - 0.5 * np.log(sigma[state]) - 0.5 * ((data[t] - mu[state] - phi[state] * data[t-1]) ** 2) / sigma[state])\n",
    "\n",
    "\n",
    "# def prediction_step(transition_matrix, filtered_probabilities, t):\n",
    "#     \"\"\"\n",
    "#     Use the dot product of the transition_matrix and the filtered_probability\n",
    "#     \"\"\"  \n",
    "#     predictions = transition_matrix.dot(filtered_probabilities[:,t])\n",
    "#     return predictions\n",
    "\n",
    "# def filtering_step(partial_likelihood, likelihood_contributions, t):\n",
    "#     \"\"\"\n",
    "#     For State in n_states\n",
    "#         Set filtered_pribabilities for a stateequal to partial_likelihood for the state divided by total likelihood.\n",
    "#     \"\"\"\n",
    "#     filtered = np.zeros(n_states)\n",
    "#     for state in range(n_states):\n",
    "#         filtered[state] = partial_likelihood[state] / likelihood_contributions[t]\n",
    "#     return filtered\n",
    "\n",
    "# def objective(initial_guess):\n",
    "#     \"\"\"\n",
    "#     Setup Arrays for Book Keeping\n",
    "#     Create Parameters\n",
    "#     for t in rainge(num_obs):\n",
    "#         ...\n",
    "#     \"\"\"\n",
    "#     # For Book Keeping\n",
    "#     num_obs = len(data)\n",
    "#     predicted_probabilities = np.zeros([n_states, num_obs+1])\n",
    "#     filtered_probabilities = np.zeros([n_states, num_obs])\n",
    "#     smoothed_probabilities = np.zeros([n_states, num_obs])\n",
    "#     likelihood_contributions = np.zeros(num_obs)\n",
    "\n",
    "\n",
    "#     # Form Model Parameters\n",
    "#     p_00, p_11, sigma, mu, phi = parameterize(initial_guess)\n",
    "\n",
    "#     # Form Transition Matrix\n",
    "#     transition_matrix = create_transition_matrix(p_00, p_11)\n",
    "\n",
    "#     # Form Initial Probabilities\n",
    "#     predicted_probabilities[[0,1],0] = calculate_initial_probabilities(transition_matrix)\n",
    "\n",
    "#     # To Hold values of Forward Filter Recursions\n",
    "#     eta = np.zeros(n_states)\n",
    "    \n",
    "#     # To Hold values of Forward Filter Recursions\n",
    "#     filters = np.zeros(n_states)\n",
    "    \n",
    "#     # To Hold values of Partial Log-Likelihoods.\n",
    "#     partial_likelihood = np.zeros(n_states)\n",
    "\n",
    "#     # The Main For Loop:\n",
    "#     for t in range(num_obs):\n",
    "#         # Calculate State Densities\n",
    "#         for state in range(n_states):\n",
    "#             eta[state] = density_function(t, state, sigma, mu, phi)\n",
    "#             partial_likelihood[state] = predicted_probabilities[state,t] * eta[state]\n",
    "\n",
    "#         # Calculate the Log-Likelihood\n",
    "\n",
    "#         likelihood_contributions[t] = np.log(np.sum(partial_likelihood))\n",
    "\n",
    "#         # Calculate the Filtering Step\n",
    "#         num0 = eta[0] * predicted_probabilities[0,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "#         num1 = eta[1] * predicted_probabilities[1,t] / (eta[0] * predicted_probabilities[0,t] + eta[1] * predicted_probabilities[1,t])\n",
    "#         filtered_probabilities[[0,1],t] = num0, num1\n",
    "#         # filtered_probabilities[:,t] = filtering_step(partial_likelihood, likelihood_contributions, t)\n",
    "\n",
    "#         # Calculate the Prediction step\n",
    "#         predicted_probabilities[[0,1],t+1] = transition_matrix.dot(filtered_probabilities[[0,1],t])\n",
    "#         #predicted_probabilities[:, t+1] = prediction_step(transition_matrix, filtered_probabilities, t)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         # print(f' Likelihood Value :  {likelihood_contributions[t]}')\n",
    "#         # print(f'  Predicted Probability:  {predicted_probabilities[:, t+1]}')\n",
    "#         # print(f' Filtered Probability :  {filtered_probabilities[:,t] }')\n",
    "#         # print(f'Eta  :  {eta}')\n",
    "#         # print(f'Partial Likelihood  :  {partial_likelihood}')\n",
    "#     # Return the Negative Sum of the Log-Likelihood\n",
    "    \n",
    "#     negative_likelihood = -np.sum(likelihood_contributions)\n",
    "\n",
    "#     return negative_likelihood\n",
    "    \n",
    "# def fit(data):\n",
    "#     \"\"\"\n",
    "#     Minimize the objective Function\n",
    "#         Use initial Guess, constraints, bounds, and arguments.\n",
    "#         Print results.\n",
    "#     \"\"\"\n",
    "\n",
    "#     # Initial Guesses\n",
    "#     variance = np.var(data)\n",
    "#     initial_guess= np.array([0.9, 0.9, np.sqrt(2*variance), np.sqrt(0.5*variance),0,0,0,0])\n",
    "\n",
    "#     # Parameter Bounds\n",
    "#     my_bounds = bounds=((0.001,0.9999),(0.001,0.9999),(0.01,None),(0.01,None),(None,None),(None,None),(None,None),(None,None))\n",
    "\n",
    "#     # Missing: Constraint, args \n",
    "\n",
    "\n",
    "#     res = minimize(objective, initial_guess, method='L-BFGS-B', bounds=my_bounds) # constraint=cons,arg=args)\n",
    "\n",
    "#     # Hessian, standard errors, print etc\n",
    "#     res.x\n",
    "#     v_hessian = res.hess_inv.todense()\n",
    "#     se_hessian = np.sqrt(np.diagonal(v_hessian))\n",
    "\n",
    "#     # The Results:\n",
    "#     estimated_parameters = res.x\n",
    "#     se = se_hessian\n",
    "#     print('P11='+str(estimated_parameters[0])+', std.errors='+str(se[0]))\n",
    "#     print('P22='+str(estimated_parameters[1])+', std.errors='+str(se[1]))\n",
    "#     print('h1='+str(estimated_parameters[2])+', std.errors='+str(se[2]))\n",
    "#     print('h2='+str(estimated_parameters[3])+', std.errors='+str(se[3]))\n",
    "#     print('mu1='+str(estimated_parameters[4])+', std.errors='+str(se[4]))\n",
    "#     print('mu2='+str(estimated_parameters[5])+', std.errors='+str(se[5]))\n",
    "#     print('phi='+str(estimated_parameters[6])+', std.errors='+str(se[6]))\n",
    "#     print('phi2='+str(estimated_parameters[7])+', std.errors='+str(se[7]))\n",
    "\n",
    "#     return estimated_parameters\n",
    "\n",
    "# def smoothed(estimates):\n",
    "    \n",
    "\n",
    "\n",
    "# my_fitted = fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a6453c-8942-498c-bfa7-b858c841a976",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting returns and filtered probabilities\n",
    "gamma=my_fitted\n",
    "y = data\n",
    "def GaussianDensity(y,m,s):\n",
    "    return np.exp(-0.5*np.log(np.pi)-0.5*np.log(s)-0.5*((y-m)**2)/s)\n",
    "#parameters\n",
    "p00    = gamma[0]\n",
    "p11    = gamma[1]\n",
    "sigma2 = gamma[2:4]**2;\n",
    "T      = len(y)\n",
    "#//transition matrix\n",
    "P = np.zeros([2,2])\n",
    "P[0]=p00, 1-p11\n",
    "P[1]=1-p00, p11\n",
    "    \n",
    "#//bookkeeping\n",
    "xi_10      = np.zeros([2,T+1])\n",
    "xi_11      = np.zeros([2,T])\n",
    "xi_1T      = np.zeros([2,T])\n",
    "lik        = np.zeros(T)\n",
    "\n",
    "#//regression:\n",
    "A  = np.vstack(((np.identity(2)-P),np.ones([1,2])))\n",
    "pi_first = np.linalg.inv(A.T.dot(A)).dot(A.T)\n",
    "pi_second=np.vstack((np.zeros([2,1]),np.ones([1,1])))\n",
    "pi=pi_first.dot(pi_second)\n",
    "xi_10[[0,1],0] = pi.T\n",
    "#//forward filter recursion\n",
    "eta=np.zeros(2)\n",
    "for t in range(T):\n",
    "    #//state densities\n",
    "    eta[0]=GaussianDensity(y[t],0,sigma2[0])\n",
    "    eta[1]=GaussianDensity(y[t],0,sigma2[1])\n",
    "        \n",
    "    #likelihood\n",
    "    #print(np.log(xi_10[[0,1],t]))\n",
    "    lik[t]   = np.log(xi_10[0,t]*eta[0]+xi_10[1,t]*eta[1])\n",
    "        \n",
    "    #filtering\n",
    "    num0=eta[0]*xi_10[0,t]/(eta[0]*xi_10[0,t]+eta[1]*xi_10[1,t])\n",
    "    num1=eta[1]*xi_10[1,t]/(eta[0]*xi_10[0,t]+eta[1]*xi_10[1,t])\n",
    "    xi_11[[0,1],t] = num0,num1\n",
    "\n",
    "    #prediction\n",
    "    xi_10[[0,1],t+1] = P.dot(xi_11[[0,1],t])\n",
    "    \n",
    "    #Backward smoother (not needed for likelihood)\n",
    "    xi_1T[:,T-1]=xi_11[:,T-1]\n",
    "    for t in range(T-2,0,-1):\n",
    "        xi_1T[:,t]=xi_11[:,t]*(P.T.dot(xi_1T[:,t+1]/xi_10[:,t+1]))\n",
    "        \n",
    "vol=np.zeros(len(y))\n",
    "for i in range(T):\n",
    "    vol[i]=xi_11[[0],i]*sigma2[0]+ (1-xi_11[[0],i])*sigma2[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720fc96a-3e29-4cfd-b2d5-175f34014549",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax=plt.subplots(2, figsize=(14,7))\n",
    "#fig.set_figheight=(9)\n",
    "#fig.set_figwidth=(16)\n",
    "fig.suptitle('log-return and filtered volatility')\n",
    "ax[0].plot(y,color='r')\n",
    "ax[1].plot(np.sqrt(vol))\n",
    "\n",
    "#Setting titles\n",
    "ax[0].title.set_text('Log-return, $x_t$')\n",
    "ax[1].title.set_text('Filtered volatility, $E[\\sigma_t|x_t,x_{t-1},...,x_1]$')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98e6744-0d5b-44a9-a9cd-4fe35b6d0256",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicted state probability, Filtered state probability and smoothed state probability\n",
    "fig, ax=plt.subplots(3, figsize=(16,9))\n",
    "#fig.tight_layout() \n",
    "\n",
    "#Adjusting size between subplots\n",
    "fig.subplots_adjust(left=None, bottom=0.025, right=None, top=None, wspace=None, hspace=None)\n",
    "#default\n",
    "#left  = 0.125  # the left side of the subplots of the figure\n",
    "#right = 0.9    # the right side of the subplots of the figure\n",
    "#bottom = 0.1   # the bottom of the subplots of the figure\n",
    "#top = 0.9      # the top of the subplots of the figure\n",
    "#wspace = 0.2   # the amount of width reserved for blank space between subplots\n",
    "#hspace = 0.2   # the amount of height reserved for white space between subplots\n",
    "\n",
    "\n",
    "ax[0].plot(1-xi_10[0,:])\n",
    "ax[1].plot(1-xi_11[0,:])\n",
    "ax[2].plot(1-xi_1T[0,:])\n",
    "\n",
    "#Setting limits on x axis\n",
    "ax[0].set_xlim(0, T)\n",
    "ax[1].set_xlim(0, T)\n",
    "ax[2].set_xlim(0, T)\n",
    "\n",
    "#Setting titles\n",
    "ax[0].title.set_text('Predicted state probability, $P(s_t=1|x_{t-1},x_{t-2},...,x_{1})$')\n",
    "ax[1].title.set_text('Filtered state probability, $P(s_t=1|x_{t},x_{t-1},...,x_{1})$')\n",
    "ax[2].title.set_text('Smoothed state probability, $P(s_t=1|x_{T},x_{T-1},...,x_{1})$')\n",
    "\n",
    "#Setting lines at 0 and 1\n",
    "ax[0].axhline(0,color='black', linestyle=\"--\")\n",
    "ax[0].axhline(1,color='black', linestyle=\"--\")\n",
    "\n",
    "ax[1].axhline(0,color='black', linestyle=\"--\")\n",
    "ax[1].axhline(1,color='black', linestyle=\"--\")\n",
    "\n",
    "ax[2].axhline(0,color='black', linestyle=\"--\")\n",
    "ax[2].axhline(1,color='black', linestyle=\"--\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd937de-f813-4cce-8848-8956ff0a9832",
   "metadata": {},
   "outputs": [],
   "source": [
    "poppopopofg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf978a09-87cb-4cc7-a4d8-5a3fcfd1e5c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e18d818-44c6-44bf-a24e-3d7916637423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1324aec-ac69-4a1b-8fd4-3577536b5a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7fc3a2d-a570-4636-9768-c66b22705618",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef72218-f779-43a3-af10-0523468c4962",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c92402b-7950-44f7-bbef-c9d6dc26a0b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe184be-2ead-444a-9c00-e727fc68cc1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62d1108-7534-4142-8d9a-4a8a988cd564",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
