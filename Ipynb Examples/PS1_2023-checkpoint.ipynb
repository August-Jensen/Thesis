{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddb6c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"statsmodels\")\n",
    "\n",
    "# Load libraries used throughout the problem set\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df9955c1",
   "metadata": {},
   "source": [
    "## Short note before.\n",
    "\n",
    "Some of the main takeaways from this problem set are\n",
    "- Build intuition on core processes from this course\n",
    "- Difference between conditional and unconditional distributions\n",
    "- Stationarity and existence of moments (and the separation of these two)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c399eea",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "\n",
    "Consider the ARCH(1) process given by <br> <br>\n",
    "$x_{t} = \\sigma_{t}z_{t}$ <br>\n",
    "$\\sigma_{t}^{2}=\\omega + \\alpha x_{t-1}^{2}$ <br> <br>\n",
    "with $z_{t}$ i.i.d $\\mathcal{N}(0,1)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e957ca",
   "metadata": {},
   "source": [
    "### Exercise 1.1 + 1.2\n",
    "- Simulate an ARCH(1) process $\\{x_{t}\\}_{t=0}^{T}$ with $T=1000$, $x_{0}=0$, $\\sigma^{2}=1$ and $\\alpha=0.4$\n",
    "\n",
    "- Plot the simulated data, histogram and density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef37752",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARCH1():\n",
    "\n",
    "    def __init__(self, α, ω=1, x0=0, T=1000, dist='Gaussian', v=6, seed=None):\n",
    "        \"\"\"\n",
    "        A class to simulate and visualize an ARCH(1) process.\n",
    "    \n",
    "        Methods:\n",
    "        simulate(): Simulate the ARCH(1) process.\n",
    "        plot_results(): Plot simulated data (returns and vol), histogram+density and QQ plot\n",
    "        plot_tail_comparison(): Plot simulated data for ARCH(1) process and another process y, as well as QQ plots for both.\n",
    "        \"\"\"\n",
    "        # Set seed if supplied to replicate results\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        \n",
    "        # Assign parameters\n",
    "        self.α         = α    # Coefficient for the ARCH(1) process\n",
    "        self.ω         = ω    # Constant term for the ARCH(1) process. Default is 1.\n",
    "        self.T         = T    # Number of time periods for the simulation. Default is 1000.\n",
    "        self.x0        = x0   # Initial value for the process. Default is 0.\n",
    "        self.dist      = dist # Distribution to use for random variables ('Gaussian' or 't'). Default is 'Gaussian'.\n",
    "        self.v         = v    # Degrees of freedom for the t-distribution (if used). Default is 6.\n",
    "        \n",
    "        # Assign x and σ2 processes\n",
    "        self.x         = np.empty(T) \n",
    "        self.sigma2    = np.empty(T)\n",
    "        \n",
    "        # Choose which distribution to draw the errors from.\n",
    "        if self.dist == \"Gaussian\":\n",
    "            self.z = np.random.normal(size=self.T)\n",
    "        elif self.dist == \"t\":\n",
    "            if self.v > 2:  # Ensure that degrees of freedom is greater than 2 for scaling\n",
    "                scale_factor = np.sqrt((self.v-2) / self.v) # Scale such that mean is 0 and var is 1\n",
    "                self.z = np.random.standard_t(df=self.v, size=self.T) * scale_factor\n",
    "            else:\n",
    "                raise ValueError(\"Degrees of freedom must be greater than 2 for scaling. (Cauchy case not implemented here)\")\n",
    "        else:\n",
    "            raise ValueError(\"Invalid distribution. Use 'Gaussian' or 't'.\")\n",
    "    \n",
    "    \n",
    "    def simulate(self):\n",
    "        for t in range(self.T):\n",
    "            if t == 0: # For t=0 we use the initial value x0 in the cond. var process to initialize.\n",
    "                self.sigma2[t] = self.ω + self.α*self.x0**2\n",
    "                self.x[t]      = np.sqrt(self.sigma2[t])*self.z[t]\n",
    "            else: # Else we use x_t-1\n",
    "                self.sigma2[t] = self.ω + self.α*self.x[t-1]**2\n",
    "                self.x[t]      = np.sqrt(self.sigma2[t])*self.z[t]\n",
    "\n",
    "        return self.x, self.sigma2\n",
    "\n",
    "    \n",
    "    def plot_results(self, figsize=(13, 13)):\n",
    "        fig, axs = plt.subplots(2, 2, figsize=figsize)\n",
    "        axs[0, 0].plot(self.x, lw=0.5, label=\"ARCH(1) process\")\n",
    "        axs[0, 0].legend()\n",
    "        axs[0, 1].plot(self.sigma2, lw=0.5, label=\"Conditional Variance\")\n",
    "        axs[0, 1].legend()\n",
    "        sns.histplot(self.x, stat=\"density\", bins=int(self.T / 25), kde=True, label='Data', ax=axs[1, 0])\n",
    "        sns.lineplot(x=self.x, y=norm.pdf(self.x, self.x.mean(), self.x.std()), color='red', label=f'N(s={self.x.std():.2f})', ax=axs[1, 0])\n",
    "        sm.qqplot(self.x, line='q', fit=True, label='ARCH(1) - QQ plot', ax=axs[1, 1])\n",
    "        axs[1, 1].legend()\n",
    "        plt.suptitle(f\"Alpha = {self.α}\", y=0.91)  # y refers to spacing between suptitle and figures\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_tail_comparison(self, y, figsize=(13, 5)):\n",
    "        fig2, axs2 = plt.subplots(1, 3, figsize=figsize)\n",
    "        axs2[0].plot(self.x, lw=0.3, label=\"ARCH(1) process\")\n",
    "        axs2[0].plot(y, lw=0.3, label=\"iid N(0,V) process\")\n",
    "        axs2[0].legend()\n",
    "        sm.qqplot(self.x, line='q', fit=True, label='ARCH(1) - QQ plot', ax=axs2[1])\n",
    "        axs2[1].legend()\n",
    "        sm.qqplot(y, line='q', fit=True, label='iid N(0,V)', ax=axs2[2])\n",
    "        axs2[2].legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a540bcb",
   "metadata": {},
   "source": [
    "#### Let us begin by simulating with $\\alpha = 0.4$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f05804",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1 = ARCH1(α=0.4, seed=123)\n",
    "arch1.simulate()\n",
    "arch1.plot_results(figsize=(14,14))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0dc8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to zoom into tail of histogram and density\n",
    "sns.histplot(arch1.x, stat=\"density\", bins=int(1000/25), kde=True, label='Data')\n",
    "sns.lineplot(x=arch1.x, y=norm.pdf(arch1.x, arch1.x.mean(), arch1.x.std()), color='red', label=f'N(s={arch1.x.std():.2f})')\n",
    "plt.xlim(-5,-2)\n",
    "plt.ylim(0,0.04)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad24304",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "- While our model is conditionally normal distributed, the unconditional (marginal) distribution is not normal!\n",
    "- Even for a modest value of $\\alpha$, we have fatter unconditional tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bcfb1d6",
   "metadata": {},
   "source": [
    "### Exercise 1.3\n",
    "With $\\alpha = 0.4$, it follows that $x_{t}$ is stationary with variance <br><br> $V(x) = \\sigma^{2}/(1-\\alpha) = 5/3$. <br><br> \n",
    "- Simulate an i.i.d $\\mathcal{N}(0,V(X))$ series and compare the tails of the two distributions by simple plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419872c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the N(0V(X)) series with V(X) = 5/3\n",
    "V = 5/3\n",
    "y = np.random.normal(0, np.sqrt(V), size=1000)\n",
    "\n",
    "arch1.plot_tail_comparison(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f543863",
   "metadata": {},
   "source": [
    "Comments\n",
    "- Even though both processes have the same unconditional variance (5/3), we see the difference in the tail behaviour due to the ARCH modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5346d19",
   "metadata": {},
   "source": [
    "## Exercise 1.4\n",
    "\n",
    "- Repeat 1-3 with $\\alpha = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165bb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 0.9\n",
    "\n",
    "arch1_ex1_4 = ARCH1(α=α, seed=2023)\n",
    "arch1_ex1_4.simulate()\n",
    "arch1_ex1_4.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2039878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 5/3\n",
    "y = np.random.normal(0, np.sqrt(V), size=1000)\n",
    "\n",
    "arch1_ex1_4.plot_tail_comparison(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec06b76",
   "metadata": {},
   "source": [
    "Comments\n",
    "\n",
    "- The higher $\\alpha$ value allows for much fatter tails as evident by both the QQ plots and the ARCH process itself."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5bcd7e",
   "metadata": {},
   "source": [
    "## Exercise 1.5\n",
    "- Repeat questions 1-2 with $\\alpha \\in \\{ 1,1.1,2 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da74f7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1_ex1_5_1 = ARCH1(α=1, seed=2023)\n",
    "arch1_ex1_5_1.simulate()\n",
    "arch1_ex1_5_1.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41392e",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1_ex1_5_2 = ARCH1(α=1.1, seed=2023)\n",
    "arch1_ex1_5_2.simulate()\n",
    "arch1_ex1_5_2.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9790f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1_ex1_5_3 = ARCH1(α=2, seed=2023)\n",
    "arch1_ex1_5_3.simulate()\n",
    "arch1_ex1_5_3.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfc4474",
   "metadata": {},
   "source": [
    "Comments\n",
    "- As $\\alpha \\geq 1$, the process $x_{t}$ no longer has a finite second order moment (variance). However it is still a stationary process!\n",
    "- Critical value for stationarity of an ARCH(1) model is roughly 3.56. See lecture notes (Part I) for table of critical values.\n",
    "- Tails are VERY fat now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12de31b6",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "Consider the ARCH(1) process given by <br> <br>\n",
    "$x_{t} = \\sigma_{t}z_{t}$ <br>\n",
    "$\\sigma_{t}^{2}=\\omega + \\alpha x_{t-1}^{2}$ <br> <br>\n",
    "with $z_{t}$ i.i.d $t_{v}(0,1)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d4b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1_ex2 = ARCH1(α=0.4, dist='t', seed=2023)\n",
    "arch1_ex2.simulate()\n",
    "arch1_ex2.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f67def",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 5/3\n",
    "y = np.random.normal(0, np.sqrt(V), size=1000)\n",
    "\n",
    "arch1_ex2.plot_tail_comparison(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9389b0e",
   "metadata": {},
   "source": [
    "Comments\n",
    "- The t distribution takes more extreme values with a higher propability, which in turn allows for more mass in the unconditional tails\n",
    "- Existance of moments still relies on $\\alpha$, but also on $v$ now!\n",
    "- We now have fatter tails than when we used Gaussian innovations. Consider the QQ plot below (especially y-axis) for the Gaussian case from exercise 1 and the new case with t-distributed innovations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a99cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this if you can't find the models further up in the notebook\n",
    "#arch1 = ARCH1(α=0.4, seed=123)\n",
    "#arch1.simulate()\n",
    "#arch1_ex2 = ARCH1(α=0.4, dist='t', seed=123)\n",
    "#arch1_ex2.simulate()\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize=(13,4))\n",
    "axs[0].plot(arch1.x, lw=0.3, label=\"N dist errors\")\n",
    "axs[0].plot(arch1_ex2.x, lw=0.3, label=\"t dist errors\")\n",
    "axs[0].legend()\n",
    "sm.qqplot(arch1.x, line='q', fit=True, label='N dist errors', ax=axs[1])\n",
    "axs[1].legend()\n",
    "sm.qqplot(arch1_ex2.x, line='q', fit=True, label='t dist errors', ax=axs[2])\n",
    "axs[2].legend()\n",
    "fig.suptitle(\"QQ-plots for alpha=0.4 when using N(0,1) and t_v(0,1) (v=6) distributed errors\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e91ee",
   "metadata": {},
   "source": [
    "## Exercise 2.4\n",
    "\n",
    "Repeat questions 2.1-2.3 with $\\alpha = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a6738c",
   "metadata": {},
   "outputs": [],
   "source": [
    "arch1_ex2_4 = ARCH1(α=0.9, dist='t', seed=2023)\n",
    "arch1_ex2_4.simulate()\n",
    "arch1_ex2_4.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22042b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = 5/3\n",
    "y = np.random.normal(0, np.sqrt(V), size=1000)\n",
    "\n",
    "arch1_ex2_4.plot_tail_comparison(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b2ad98",
   "metadata": {},
   "source": [
    "Comments\n",
    "- For v=6, we still have that the second order moments are finite when $\\alpha$ < 1\n",
    "- Similar to 1.4, but now the t-distributions allows for more mass in the tails \n",
    "- More extreme tails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e9487e",
   "metadata": {},
   "source": [
    "## Exercise 2.5\n",
    "\n",
    "Repeat questions 1-2 with $\\alpha \\in \\{ 1, 1.1, 2 \\}$ and $v \\in \\{ 4, 8, 99 \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861ffcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose α and v to your liking.\n",
    "\n",
    "α = 2\n",
    "v = 4\n",
    "\n",
    "arch1_ex2_5 = ARCH1(α=α, dist='t', v=v, seed=2023)\n",
    "arch1_ex2_5.simulate()\n",
    "arch1_ex2_5.plot_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9e75bb",
   "metadata": {},
   "source": [
    "Comments\n",
    "- Try the different combinations to see how the plots change for different alpha and v values (For v = 6, you may even have alpha < 4.5 and still have a stationary process!)\n",
    "- For $v \\rightarrow \\infty $, the t distribution will tend to the Gaussian - Note that it will still NOT be unconditional Gaussian. We are simply in the case as before (exercise 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c7c094",
   "metadata": {},
   "source": [
    "# Exercise 3\n",
    "\n",
    "Consider the stochastic process as given by\n",
    "\n",
    "$x_{t} = \\mu + \\epsilon_{t}$\n",
    "\n",
    "with $\\epsilon_{t}$ an i.i.d sequence. With $\\{x_{t}\\}_{t=1}^{T}$ the average is given by $\\bar{x} = T^{-1}\\sum_{t=1}^{T}x_{t}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d44be8",
   "metadata": {},
   "source": [
    "## Exercise 3.1+3.2\n",
    "\n",
    "* With $\\epsilon_{t}$ i.i.d $\\mathcal{N}(0,1)$ argue that $\\bar{x} \\xrightarrow p E(x_{t}) = \\mu$\n",
    "* Simulate $x_{t}$ for $T=1000$ and $\\mu = 1$. Plot $\\bar{x}$ as a function of N, $\\bar{x}(N) = N^{-1}\\sum_{t=1}^{N} x_{t}$ with $N=10,100,\\dots,T/2,\\dots,T$. Comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0999e1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "T = 1000\n",
    "μ   = 1\n",
    "ϵ = np.random.normal(size=T)\n",
    "x_t = μ + ϵ\n",
    "\n",
    "N_values = np.arange(10,T+1,10)\n",
    "x_bar_values = [np.mean(x_t[:N]) for N in N_values]\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(N_values, x_bar_values, lw=0.3, label='$\\\\bar{x}(N)$')\n",
    "plt.ylim(0.6,1.4)\n",
    "plt.axhline(y=μ, color='r', linestyle='--', label='$\\mu$')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('$\\\\bar{x}(N)$')\n",
    "plt.title('Convergence of $\\\\bar{x}(N)$ to $\\mu$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955c6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "520070ed",
   "metadata": {},
   "source": [
    "## Exercise 3.3\n",
    "\n",
    "Assume that $\\epsilon_{t}$ is i.i.d $t_{4}(0,1)$ distributed. Argue that $\\bar{x} \\xrightarrow p E(x_{t}) = \\mu$ and repeat question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f410d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "T = 1000\n",
    "v = 4\n",
    "ϵ = np.sqrt((v-2)/v)*np.random.standard_t(df=v, size=T)\n",
    "x_t = μ + ϵ\n",
    "\n",
    "N_values = np.arange(10,T+1,10)\n",
    "x_bar_values = [np.mean(x_t[:N]) for N in N_values]\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(N_values, x_bar_values, lw=0.3, label='$\\\\bar{x}(N)$')\n",
    "plt.ylim(0.6,1.4)\n",
    "plt.axhline(y=μ, color='r', linestyle='--', label='$\\mu$')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('$\\\\bar{x}(N)$')\n",
    "plt.title('Convergence of $\\\\bar{x}(N)$ to $\\mu$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f062c66c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57fe5c6a",
   "metadata": {},
   "source": [
    "## Exercise 3.4\n",
    "\n",
    "Assume that $\\epsilon_{t}$ is i.i.d $t_{1}(0,1)$ (or Cauchy) distributed. In this case, no convergence holds (why not?) - illustrate by simulations as in question 2Argue that $\\bar{x} \\rightarrow^{p} E(x_{t}) = \\mu$ and repeat question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d65bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(123)\n",
    "T = 1000\n",
    "ϵ = np.random.standard_cauchy(size=T)\n",
    "x_t = μ + ϵ\n",
    "\n",
    "N_values = np.arange(10,T+1,10)\n",
    "x_bar_values = [np.mean(x_t[:N]) for N in N_values]\n",
    "\n",
    "plt.figure(figsize=(13,8))\n",
    "plt.plot(N_values, x_bar_values, lw=0.3, label='$\\\\bar{x}(N)$')\n",
    "#plt.ylim(0.6,1.4)\n",
    "plt.axhline(y=μ, color='r', linestyle='--', label='$\\mu$')\n",
    "plt.xlabel('N')\n",
    "plt.ylabel('$\\\\bar{x}(N)$')\n",
    "plt.title('Convergence of $\\\\bar{x}(N)$ to $\\mu$')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21586ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0375cc33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406ff83d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946e3bbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
